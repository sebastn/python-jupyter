{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today is the day! Finally, you will enter the mystical magical world of Machine Learning. Let us begin!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In today's workshop, we will introduce you to two famous Machine Learning models. The first one is **K-Nearest-Neighbour** and the second one is a __Decision Tree Model__. In this workshop, everything you have learned so far in the previous weeks will come together. This means that you not only have to use NumPy, but also Pandas functionalities. But don't worry, as responsible tutors, we will stand on your side. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments for slides:\n",
    "\n",
    "- What is Machine Learning\n",
    "\n",
    "- Training vs Testing\n",
    "- Models\n",
    "    - KNN \n",
    "    - Decision Tree\n",
    "    \n",
    "- Evaluation\n",
    "    - Accuracy \n",
    "    \n",
    "- Optimisation\n",
    "    - Hyper Parameter\n",
    "\n",
    "- Overfitting vs. Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we work with the Breast Cancer Wisconsin (Diagnostic) Database. The goal is to create a classifier that can with the diagnosis of patients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Loads the breast cancer dataset\n",
    "cancer = load_breast_cancer() \n",
    "\n",
    "# Dataset description\n",
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great! We have downloaded the cancer dataset. Let's deep dive into it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Let's print the dataset\")\n",
    "print(cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see this is quite confusing. Maybe, we know more if we know the data type\n",
    "print(\"The data type is: \")\n",
    "print(type(cancer))\n",
    "\n",
    "# For further explication: https://scikit-learn.org/stable/datasets/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the features\n",
    "print(\"The feature data looks like this: \")\n",
    "print(cancer.data, \"\\n\")\n",
    "print(\"The data type is: \")\n",
    "print(type(cancer.data))\n",
    "\n",
    "print()\n",
    "# Now, let's look at the labels / targets\n",
    "print(\"The label data looks like this: \")\n",
    "print(cancer.target, \"\\n\")\n",
    "print(\"The data type is: \")\n",
    "print(type(cancer.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we start now, there 2 quick things to check/do. \n",
    "\n",
    "First of all, NumPy is cool, but let us work with Pandas. It is just way more comfy.. :)\n",
    "\n",
    "And secondly, what does 0 and what does 1 mean...we should really understand our labelling before we do some predicting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the data into Pandas dataframe\n",
    "\n",
    "# This will create a data frame with the cancer data and features as columns\n",
    "df_cancer = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)\n",
    "\n",
    "print(\"Dataframe without label column\")\n",
    "print(df_cancer.shape, \"\\n\")\n",
    "\n",
    "# In order to get target as additional column we have to create a pandas series\n",
    "df_cancer['target'] = pd.Series(cancer.target)\n",
    "\n",
    "print(\"Dataframe with label column\")\n",
    "print(df_cancer.shape, \"\\n\")\n",
    "\n",
    "df_cancer.head() # Gives first rows of newly created DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_ser = df_cancer['target'].value_counts() # Creates a series which counts the number of 0 and 1s\n",
    "\n",
    "\n",
    "print(type(cancer_ser))\n",
    "cancer_ser\n",
    "\n",
    "# Okay, now we actually know the share of our classes\n",
    "# cancer_ser.rename(index = {1: 'benign', 0: 'malignant'}, inplace=True) # Changes the naming of the index\n",
    "# print(cancer_ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wicked! We will focus on the train and test split of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the train_test_split functionality\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preparing X and Y values\n",
    "X = df_cancer.iloc[:, :-1]\n",
    "y = df_cancer.iloc[:, -1]\n",
    "\n",
    "print(\"Initial data dimensions\")\n",
    "print(X.shape)\n",
    "print(y.shape, \"\\n\")\n",
    "\n",
    "# Creates four data sets with training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print(\"After train / test split\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drum roll....It is time for K-Nearest-Neighbour!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install KNN model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Defining neighbours\n",
    "k = 1\n",
    "\n",
    "# Creating a KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors = k) \n",
    "\n",
    "# Training the model with training data\n",
    "knn.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using then KNN classifier, we predict the class labels using the mean value for each feature.\n",
    "\n",
    "In order to implement this, we will use `cancerdf.mean()[:-1].values.reshape(1, -1)` which gets the mean value for each feature, ignores the label column, and finally reshapes the data from 1 dimension to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the predictions based on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"Predictions are: \")\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Prediction With Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evalute the performance of the classifier, the score (mean accuracy) of the KNN classifier will be computed for  `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_acc = knn.score(X_test, y_test)\n",
    "\n",
    "print(f\"The accuracy of the KNN classifier is: {knn_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us visualize this result (comparing training vs. testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mal_train_X = X_train[y_train==0]\n",
    "mal_train_y = y_train[y_train==0]\n",
    "ben_train_X = X_train[y_train==1]\n",
    "ben_train_y = y_train[y_train==1]\n",
    "\n",
    "mal_test_X = X_test[y_test==0]\n",
    "mal_test_y = y_test[y_test==0]\n",
    "ben_test_X = X_test[y_test==1]\n",
    "ben_test_y = y_test[y_test==1]\n",
    "\n",
    "scores = [knn.score(mal_train_X, mal_train_y), knn.score(ben_train_X, ben_train_y), \n",
    "          knn.score(mal_test_X, mal_test_y), knn.score(ben_test_X, ben_test_y)]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot the scores as a bar chart\n",
    "bars = plt.bar(np.arange(4), scores, color=['#4c72b0','#4c72b0','#55a868','#55a868'])\n",
    "\n",
    "# directly label the score onto the bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.gca().text(bar.get_x() + bar.get_width()/2, height*.90, '{0:.{1}f}'.format(height, 2), \n",
    "                 ha='center', color='w', fontsize=11)\n",
    "\n",
    "plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "# remove the frame of the chart\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.xticks([0,1,2,3], ['Malignant\\nTraining', 'Benign\\nTraining', 'Malignant\\nTest', 'Benign\\nTest'], alpha=0.8);\n",
    "plt.title('Training and Test Accuracies for Malignant and Benign Cells', alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know now, the KNN classifier has a hyper-parameter to tune. It's **K** value. In this first challenge, compute and plot the accuracy of the KNN performance for the values k: {1,2,3,4,5,6,7,8,9,10}\n",
    "\n",
    "**What is the best K-value for your model ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the k value with the best score\n",
    "k = \n",
    "# Hint np.argmax\n",
    "best_score = \n",
    "\n",
    "print(f\"The best score is: {best_score}\" )\n",
    "print(f\"The best score, you get with k = {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We made it! Our first Machine Learning use case!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it your turn to work on real life use case, tweark the data in the right manner and create a model. This time, you will use the Decision Tree model. Of course, you can also try the KNN model on this use case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge II \n",
    "\n",
    "Alright, this is quite an oldie but really important and cool. We will predict hand-written digits!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset description\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to know the dimensionality of the data. \n",
    "\n",
    "**What are the dimensions of digits.data?**\n",
    "\n",
    "and **what are the dimensions of digits.targets?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us quickly plot the data with the command below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run the code\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
    "            transform=ax.transAxes, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now create an np.array Y_digit which holds your labels, and further an np.array X_digit which holds the bit matrices. When you have the data seperately stored in X and Y, use the scikit function to split the data in a test and training set!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to check the dimensions split of your training and test set, print the X_train and y_train dimension.**\n",
    "\n",
    "**How big is your training set now?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "This time, we will use a DT classifier to work with X_train and y_train\n",
    "\n",
    "**Hint:** Here you will find the info how to set-up your Decision Tree in Sklearn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laod the Decision Tree model from Sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Decision Tree model and train it with your training data (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree model instance \n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of your Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classes for X_test and save it to y_pred\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's have a closer look on our predictions. Plot the first element of X_test (this should be an image) and plot the first element of y_pred (this is an integer)** \n",
    "\n",
    "**Is the predictions accurate?**\n",
    "\n",
    "**HINT 1:** The function in order to plot the image is: plt.imshow(first_X_value, cmap='binary', interpolation='nearest')\n",
    "\n",
    "**HINT 2:** Maybe, you have to reshape the first element of your X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your predictions with y_test. What is your accuracy? --> Save your accuracy in variable dt_acc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that our model has its limitations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"This is our target test set: {y_test}\", \"\\n\")\n",
    "\n",
    "print(f\"This is our target prediction set: {y_pred}\", \"\\n\")\n",
    "\n",
    "# We can see that the second element was not correctly predicted, the prediction says it is a 3, but it is actually a 3...damn it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_second = X_test[1].reshape(8,8)\n",
    "print(X_second.shape, \"\\n\")\n",
    "\n",
    "print(f\"The second prediction is a: {y_pred[1]}\", \"\\n\")\n",
    "print(f\"The corresponding image is a: \")\n",
    "plt.imshow(X_second, cmap='binary', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you can create a KNN classifier and compute its performance for this task!\n",
    "\n",
    "### Plot the second prediction, to see if  the classifier got it right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This challenge is optional!\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build the best classifier, train it and predict the values\n",
    "knn = KNeighborsClassifier(n_neighbors = 3) \n",
    "knn.fit(X_train, y_train)\n",
    " \n",
    "y_pred2 = knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_second = X_test[1].reshape(8,8)\n",
    "print(X_second.shape, \"\\n\")\n",
    "\n",
    "print(f\"The second prediction is a: {y_pred2[1]}\", \"\\n\")\n",
    "print(f\"The corresponding image is a: \")\n",
    "plt.imshow(X_second, cmap='binary', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WOOOOW, the prediction is right! KNN, with k=3 did a great job!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats! You did it! You officially completed our Python workshop series. We hope that enjoyed it as much as we did. \n",
    "\n",
    "![great](img/great.jpg)\n",
    "\n",
    "\n",
    "### Learning to program can be very challenging in the beginning (like everything, lol). But with the concepts and tools, we introduced, you should be able to tackle your own challenges.\n",
    "\n",
    "### In the upcoming months, we will sent you a feedback form. We would love to hear your feedback in order to improve this workshop series as much as possible. \n",
    "\n",
    "#### Until then...Don't forget: https://www.youtube.com/watch?v=SJUhlRoBL8M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional info about ML (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to give you also a notion about regression tasks, we quickly introduce Linear Regression. This model is very popular and quite efficient in its prediction. Of course, it has its limitations. Run the example by your own and see how you can use Machine Learning for a real value prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first use case, we will predict the y value given, some x coordinates. First, we download the linear model from sklearn. We also download the train_test_split and the r2_score functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import  r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # Just generates a random set of variables\n",
    "\n",
    "n = 100 # Number of data points\n",
    "x = np.linspace(0,10,n) + np.random.randn(n)/5\n",
    "y = np.sin(x)+x/6 + np.random.randn(n)/10\n",
    "\n",
    "# Let's have quick look at the data dimensions\n",
    "print(\"Orignal data\")\n",
    "print(x.shape)\n",
    "print(y.shape, \"\\n\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0) # Train_test_plit function\n",
    "\n",
    "# Okay, how did the dimensions change\n",
    "print(\"After train / test split\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape, \"\\n\")\n",
    "\n",
    "# Necessary reshaping for later data manipulation\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "print(\"Properly reshaped\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us plot the data\n",
    "def plot_data():\n",
    "    plt.figure()\n",
    "    plt.scatter(X_train, y_train, label='training data')\n",
    "    plt.scatter(X_test, y_test, label='test data')\n",
    "    plt.legend(loc=4);\n",
    "    \n",
    "plot_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: ', regr.coef_,  \"\\n\")\n",
    "\n",
    "# The mean squared error\n",
    "print(f\"Mean squared error: {mean_squared_error(y_test, y_pred)}\",  \"\\n\")\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print(f\"R2 score: {r2_score(y_test, y_pred)}\",   \"\\n\")\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(X_test, y_test,  color='blue')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz: Is this underfitting or overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
